import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import plotly.graph_objects as go
import warnings

warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')

st.set_page_config(
    page_title="Pr√©dictions Multi-Mod√®les",
    page_icon="üîÆ",
    layout="wide"
)

st.title("üîÆ Application de Pr√©dictions Multi-Mod√®les")
st.markdown("---")

@st.cache_resource
def load_models():
    """Charge les mod√®les pr√©-entra√Æn√©s"""
    try:
        models = {
            'Random Forest': joblib.load('models/random_forest.pkl'),
            'K Nearest Neighbors': joblib.load('models/knn.pkl'),
            'Logistic Regression': joblib.load('models/logistic_regression.pkl'),
            'Decision Tree': joblib.load('models/decision_tree.pkl'),
            'Support Vector Machine': joblib.load('models/suport_vector_machine.pkl'),
        }
        return models
    except FileNotFoundError as e:
        st.error(f"Erreur lors du chargement des mod√®les: {e}")
        st.stop()

@st.cache_resource
def load_scaler():
    """Charge le scaler pr√©-entra√Æn√© si disponible"""
    try:
        scaler = joblib.load('models/scaler.pkl')
        return scaler
    except FileNotFoundError:
        scaler = StandardScaler()
        scaler.mean_ = np.array([1.0, 0.3, 0.4, 0.5])
        scaler.scale_ = np.array([1.0, 0.46, 0.49, 0.5])
        return scaler

with st.spinner("Chargement des mod√®les..."):
    models = load_models()
    scaler = load_scaler()

st.success("Mod√®les charg√©s avec succ√®s!")

st.subheader("Faire des pr√©dictions")

model_choice = st.selectbox(
    "Choisir un mod√®le pour les pr√©dictions:",
    list(models.keys()),
    help="S√©lectionnez le mod√®le que vous souhaitez utiliser"
)

st.write(f"**Mod√®le s√©lectionn√©:** {model_choice}")

feature_columns = ['Oldpeak', 'ChestPainType_ASY', 'ExerciseAngina_Y', 'ST_Slope_Flat']
feature_descriptions = {
    'Oldpeak': 'D√©pression ST induite par l\'exercice (0-4)',
    'ChestPainType_ASY': 'Type de douleur thoracique asymptomatique (0=Non, 1=Oui)',
    'ExerciseAngina_Y': 'Angine induite par l\'exercice (0=Non, 1=Oui)',
    'ST_Slope_Flat': 'Pente du segment ST plate (0=Non, 1=Oui)'
}

st.write("### Saisie des caract√©ristiques")
prediction_inputs = {}
cols = st.columns(2)

for i, feature in enumerate(feature_columns):
    with cols[i % 2]:
        if feature in ['ChestPainType_ASY', 'ExerciseAngina_Y', 'ST_Slope_Flat']:
            prediction_inputs[feature] = st.selectbox(
                f"{feature}:",
                [0, 1],
                index=0,
                help=feature_descriptions[feature]
            )
        else:
            prediction_inputs[feature] = st.number_input(
                f"{feature}:",
                min_value=0.0,
                max_value=6.0,
                value=1.0,
                step=0.1,
                help=feature_descriptions[feature]
            )

if st.button("Faire la pr√©diction", type="primary"):
    input_data = np.array([list(prediction_inputs.values())])
    
    selected_model = models[model_choice]
    
    if model_choice in ['Logistic Regression', 'Support Vector Machine']:
        input_data_scaled = scaler.transform(input_data)
        prediction = selected_model.predict(input_data_scaled)[0]
        
        if hasattr(selected_model, 'predict_proba'):
            probability = selected_model.predict_proba(input_data_scaled)[0]
            prob_positive = probability[1]
            prob_negative = probability[0]
        else:
            decision_score = selected_model.decision_function(input_data_scaled)[0]
            prob_positive = 1 / (1 + np.exp(-decision_score))
            prob_negative = 1 - prob_positive
    else:
        prediction = selected_model.predict(input_data)[0]
        
        if hasattr(selected_model, 'predict_proba'):
            probability = selected_model.predict_proba(input_data)[0]
            prob_positive = probability[1]
            prob_negative = probability[0]
        else:
            prob_positive = float(prediction)
            prob_negative = 1 - prob_positive
    
    st.markdown("---")
    st.subheader("R√©sultats de la pr√©diction")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="Pr√©diction",
            value=f"Classe {int(prediction)}",
            delta="Positif" if prediction == 1 else "N√©gatif"
        )
    
    with col2:
        st.metric(
            label="Probabilit√© Classe Positive",
            value=f"{prob_positive:.1%}",
            delta=f"{prob_positive:.4f}"
        )
    
    with col3:
        st.metric(
            label="Probabilit√© Classe N√©gative",
            value=f"{prob_negative:.1%}",
            delta=f"{prob_negative:.4f}"
        )
    

    st.subheader("D√©tails de la pr√©diction")
    
    with st.expander("Valeurs d'entr√©e utilis√©es"):
        input_df = pd.DataFrame({
            'Caract√©ristique': list(prediction_inputs.keys()),
            'Valeur': list(prediction_inputs.values()),
            'Description': [feature_descriptions[k] for k in prediction_inputs.keys()]
        })
        st.dataframe(input_df, use_container_width=True)
    
    st.subheader("Interpr√©tation")
    
    if prob_positive > 0.7:
        st.success("**Risque √©lev√©** - Le mod√®le pr√©dit une forte probabilit√© de classe positive")
    elif prob_positive > 0.3:
        st.warning("**Risque mod√©r√©** - Le mod√®le indique une probabilit√© interm√©diaire")
    else:
        st.info("**Risque faible** - Le mod√®le pr√©dit une faible probabilit√© de classe positive")
    
    confidence = max(prob_positive, prob_negative)
    st.write(f"**Niveau de confiance:** {confidence:.1%}")
    
    if confidence > 0.8:
        st.success("Pr√©diction tr√®s fiable")
    elif confidence > 0.6:
        st.warning("Pr√©diction moyennement fiable")
    else:
        st.error("Pr√©diction peu fiable")

st.markdown("---")
st.subheader("Informations sur les mod√®les")

model_info = {
    'Random Forest': 'Ensemble de arbres de d√©cision qui vote pour la pr√©diction finale',
    'K Nearest Neighbors': 'Classifie bas√© sur les k voisins les plus proches',
    'Logistic Regression': 'R√©gression logistique pour la classification binaire',
    'Decision Tree': 'Arbre de d√©cision simple bas√© sur des r√®gles',
    'Support Vector Machine': 'Machine √† vecteurs de support pour la classification'
}

for model, description in model_info.items():
    st.write(f"**{model}:** {description}")

with st.expander("Informations techniques"):
    st.write("""
    **Caract√©ristiques utilis√©es:**
    - **Oldpeak**: D√©pression du segment ST induite par l'exercice par rapport au repos
    - **ChestPainType_ASY**: Indicateur de douleur thoracique asymptomatique
    - **ExerciseAngina_Y**: Pr√©sence d'angine induite par l'exercice
    - **ST_Slope_Flat**: Pente du segment ST plate pendant l'exercice
    
    **Notes:**
    - Les mod√®les Logistic Regression et SVM utilisent des donn√©es normalis√©es
    - Les probabilit√©s sont calcul√©es diff√©remment selon le type de mod√®le
    - La confiance est bas√©e sur la probabilit√© maximale entre les deux classes
    """)

st.markdown("---")
st.markdown("**Application cr√©√©e avec Streamlit | Mod√®les bas√©s sur scikit-learn**")